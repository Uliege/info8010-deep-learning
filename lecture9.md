class: middle, center, title-slide

# Deep Learning

Lecture 9: Attention and transformer networks

<br><br>
Prof. Gilles Louppe<br>
[g.louppe@uliege.be](g.louppe@uliege.be)

???

R: https://jalammar.github.io/illustrated-gpt2/
R: https://twitter.com/Ben_Hoov/status/1183823783754371076?s=03  --> BERT visualization
http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf

R: 1912.01412

R: google meena

https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/

R: set transformer https://arxiv.org/abs/1810.00825